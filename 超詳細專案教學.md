# 超詳細專案教學

> 適用對象：剛入門機器學習 / 深度學習，想透過此專案練習多任務文字分類的學生或工程師。以下內容將從零開始，逐步介紹每一個概念、設定與操作，並解釋為什麼需要這樣設計。

---

## 1. 專案目標與背景

### 1.1 什麼是多任務分類（Multi-Task Classification）？
- **多任務學習 (Multi-Task Learning)**：讓一個模型同時學習兩個或以上的任務，利用任務間的共享知識提升表現。
- 在本專案中，我們同時預測 **Primary** 與 **Secondary** 標籤（兩層分類），例如：
  - Primary：BUG, FEATURE_REQUEST, UI/UX, ...
  - Secondary：ACCOUNT, TRANSACTION, ...
- 相較於獨立訓練兩個模型，這樣做可以：
  1. 共用 Transformer 編碼器（如 DeBERTa、RoBERTa），節省訓練資源。
  2. 彼此提供正規化效果（regularization），降低過擬合。
  3. 在資料量有限時，更有效利用資訊。

### 1.2 為什麼需要這個專案架構？
- **清楚的資料流程**：從資料切分、訓練、超參數搜尋到穩定性評估，每個步驟都模組化。
- **設定檔驅動**：所有可調整參數都放在 YAML，讓你不用改動 Python 也能切換模型或資料。
- **可重複、可擴充**：統一入口 `python -m src.main`，確保每次執行順序一致，減少“忘記執行某個腳本”的意外。

---

## 2. 必備名詞與觀念

| 名詞 | 說明 | 在本專案的位置 |
|------|------|----------------|
| **Transformer** | 一種常見於 NLP 的模型架構，使用注意力機制 | `training.model_name` 預設使用 `IDEA-CCNL/Erlangshen-DeBERTa-v2-320M-Chinese` |
| **Dataset Split** | 將資料分成訓練集、測試集（或驗證集） | `data.split` stage 可自動切分 |
| **Hyperparameter Tuning** | 調整非模型參數（例如學習率、batch size）以獲得最佳表現 | `tuning` stage 使用 Optuna 自動搜尋 |
| **Weighted Sampling** | 依據樣本頻率調整抽樣機率，常用於不平衡資料 | `training.weighted_sampler` |
| **Focal Loss** | 針對不平衡資料的損失函數，降低簡單樣本權重，聚焦困難樣本 | `training.use_focal` 與 `focal_gamma` |
| **Artifact** | 執行後產生的成果，如模型權重、指標報表、圖表 | `artifacts/` |

---

## 3. 環境準備與安裝（一步一步）

### 3.1 安裝前檢查
1. `python --version` 是否 ≥ 3.9？
2. 是否具備 Git 與 SSH（若要使用 SSH clone）？
3. 是否有 GPU？如果有，記得安裝對應 CUDA 版本的 PyTorch。

### 3.2 建立虛擬環境
```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3.3 安裝依賴
```powershell
pip install --upgrade pip
pip install -e .
```
- `pip install -e .` 代表以 *editable* 模式安裝，專案內的程式碼修改會即時生效。
- 依賴會由 `pyproject.toml` 讀取，不需手動安裝一次次。

### 3.4 目錄結構概覽
```
.
├── configs/                  # 設定檔（default.yaml / logging.yaml）
├── input_train_and_test_json/ # 預設資料夾（放 train/test JSON）
├── src/                      # 程式核心（資料處理、模型、pipeline）
├── docs/                     # 文件（quickstart, 本教學可放此處）
├── artifacts/                # 執行後輸出（會自動建立）
├── train_mtc.py 等舊腳本     # 提供 CLI wrapper，內部呼叫新架構
└── README.md / 本教學        # 操作手冊
```

---

## 4. 資料格式與放置

### 4.1 資料來源
- 預期你已經有標註好的 JSON / JSONL
- 每筆資料至少包含：
  ```json
  {
    "text": "使用者回報內容…",
    "primary": "BUG",
    "secondary": "TRANSACTION"
  }
  ```
- 若欄位名稱不同，可在 `configs/default.yaml` 中調整 `data.text_field` 等欄位。

### 4.2 預設放置位置
- `input_train_and_test_json/train_set_xxx.json`
- `input_train_and_test_json/test_set_xxx.json`
- 如果尚未分割資料，可以使用 `split` stage 自動切分。

### 4.3 使用 split stage 的流程
1. 修改設定檔：
   ```yaml
   data:
     split:
       enabled: true
       input_path: ../data/raw/all_data.json
   ```
2. 執行：
   ```powershell
   python -m src.main --config configs/default.yaml --stages split
   ```
3. 程式會輸出新檔案（依 `train_template` 與 `test_template` 命名），並更新設定中的 `data.train_file` / `data.test_file`。

---

## 5. 設定檔（`configs/default.yaml`）深入解析

### 5.1 project 區塊
- `seed`：隨機種子，確保結果可重現。
- `output_root`：所有 artifacts 統一收納位置。
- `logging.config`：可替換成自己的 logging 設定檔。

### 5.2 pipeline 區塊
- `stages`：定義執行順序。一般狀況為 `split` → `train` → `tune` → `stability`。
- 你可以移除或調整順序，例如只想執行 `train` 與 `stability`。

### 5.3 data 區塊
- `root_dir`：訓練/測試資料所在資料夾。
- `split` 子區塊提供切分設定：`test_size`、`stratify_key` 等。
- `timestamp_format` 決定輸出檔案名稱格式。

### 5.4 labels 區塊
- 列出可用 Primary / Secondary 類別
- 程式會自動建立映射（label ↔ id）；若訓練資料出現設定外的標籤會被忽略。

### 5.5 training 區塊
- `model_name`：HuggingFace 模型 ID。
- `epochs`、`batch_size`、`learning_rate`、`max_length`：常用調整項。
- `use_focal` / `focal_gamma`：處理不平衡資料的選項。
- `weight_primary` / `weight_secondary`：是否使用 class weight。
- `weighted_sampler`：啟用後，DataLoader 會用 WeightedRandomSampler。
- `fp16_auto`：若 GPU 支援混合精度，會自動啟用 FP16。

### 5.6 tuning 區塊
- `enabled`：開啟超參數搜尋。
- `trials`：Optuna 試驗次數。
- `search_space`：定義待搜尋參數及分佈，例如 `loguniform`（對數空間）、`categorical` 等。

### 5.7 stability 區塊
- `runs`：重複訓練次數。
- `base_seed`：第一個 run 的 seed。
- 此 stage 主要統計不同 seed 下指標的平均與標準差。

---

## 6. Pipeline Stage 詳解

### 6.1 split stage
- 功能：將原始資料按照比例切成 train/test。
- 為什麼要先做？
  1. 確保資料切分可重現（依 `random_seed`）。
  2. 讓之後的 `train` stage 直接讀取既有檔案，避免手動找最新檔案。
- 注意事項：需提供 `split.input_path`，且資料必須包含 stratify 欄位（預設 `primary`）。

### 6.2 train stage
- 功能：
  - 載入 tokenizer、建立 dataset (`ReviewDataset`)
  - 建立多任務模型 (`MultiTaskClassifier`)，輸出 primary / secondary logits
  - 使用 HuggingFace `Trainer` 訓練
  - 儲存指標與圖表
- 為什麼使用 HuggingFace Trainer？
  - 內建訓練迴圈、混合精度、callback 等機制
  - 易於客製化（例如自訂 loss、sampler）
- 訓練結果：
  - `metrics_<timestamp>.json`
  - Confusion Matrix（CSV / PNG）
  - `predictions_<timestamp>.csv`
  - `label_map.json`

### 6.3 tune stage
- 功能：透過 Optuna 自動搜索最佳超參數。
- 流程：
  1. 讀取 `tuning.search_space`
  2. 每個 trial 會複製 training 設定並覆寫部分參數
  3. 進行 train stage（設 `run_name = trial_xxx`）
  4. 回傳 macro F1 平均作為最佳化目標
- 輸出：
  - `optuna_best.json`：最佳結果
  - `optuna_trials.csv`：所有試驗詳情
- 為什麼 Optuna？
  - 支援多種搜尋策略（random, TPE, CMA-ES）
  - 介面簡單，能快速整合到既有訓練程式

### 6.4 stability stage
- 功能：檢查模型在不同隨機種子下的穩定度。
- 流程：
  1. 以 `base_seed` 為起點，逐 run 加 1
  2. 每一次訓練皆會輸出 metrics
  3. 最後計算平均與標準差
- 為什麼要做？
  - 多任務模型對於資料不平衡、初始權重十分敏感，評估穩定度能提供更可靠的指標。

---

## 7. 程式碼架構導覽

| 模組 | 說明 |
|------|------|
| `src/data/io.py` | 讀寫 JSON / JSONL、DataFrame Export |
| `src/data/split.py` | 切分資料並輸出固定命名檔案 |
| `src/mtc/dataset.py` | 建立 `ReviewDataset`，回傳 tokenized tensor 與 label |
| `src/mtc/modeling.py` | 定義多任務模型、FocalLoss、pooling |
| `src/mtc/training.py` | 包裝 Trainer、計算 class weights、評估指標 |
| `src/pipeline/stages.py` | 控制 stage 執行，包含 split/train/tune/stability |
| `src/utils/config.py` | 讀取 YAML、解析路徑、建構 dataclass 設定 |
| `src/utils/logging.py` | 設定 logging（dictConfig 或 basicConfig） |
| `src/main.py` | CLI 入口；解析參數後依序執行 stage |

---

## 8. 執行流程總結（圖解）

```
┌────────────┐
│ configs    │
│ default.yaml │
└──────┬─────┘
       │ load_project_config()
       ▼
┌────────────┐
│ Pipeline   │
│ STAGE LOOP │
└──────┬─────┘
       │        ┌────────────┐
       │ split? │ data/split │---> train/test JSON
       │        └────────────┘
       │        ┌────────────┐
       ├ train? │ mtc/training│---> artifacts/training/
       │        └────────────┘
       │        ┌────────────┐
       ├ tune?  │ Optuna loop │---> artifacts/tuning/
       │        └────────────┘
       │        ┌────────────┐
       └ stability? │ repeats │---> artifacts/stability/
                └────────────┘
```

---

## 9. 進階議題與推薦實踐

### 9.1 標籤不平衡的處理
- 啟用 `training.weighted_sampler` 或 `weight_primary/secondary`
- 啟用 `use_focal`，聚焦困難樣本
- 觀察 `metrics.json` 的 `classification_report` 是否各類別 F1 達標

### 9.2 更換模型
- 修改 `training.model_name`
- 注意：不同模型的 `max_length` 與 `tokenizer` 需求可能不同
- 若要使用 LoRA，可在 `src/mtc/modeling.py` 擴增為 PEFT 結構

### 9.3 加入自訂特徵或任務
- 在 `src/data/io.py` 增加資料處理函式
- 在 `ReviewDataset` 中加入額外欄位（例如 sentiment score）
- 在模型 forward 中接受新的輸入並融合到 head

### 9.4 自動化與排程
- 建議使用 cron / GitHub Actions 定期執行 `python -m src.main --config ... --stages train`
- 可在成功訓練後自動上傳 `metrics.json` 至監控系統

---

## 10. 常見問題與排錯策略

| 問題 | 可能原因 | 解法 |
|------|----------|------|
| `FileNotFoundError: train/test` | `data.root_dir` 或檔名不匹配 | 檢查設定檔；確認 JSON 位於資料夾中 |
| `ImportError: No module named optuna` | 未安裝 optuna | `pip install optuna` 或關閉 tune stage |
| GPU 記憶體不足 | batch size 太大或模型太重 | 調低 `batch_size`、縮短 `max_length`，必要時改用 CPU |
| 指標不穩定 | 標籤不平衡或 seed 變動 | 使用 `weighted_sampler`、增加資料量或執行 stability stage |
| `UnicodeDecodeError` | 資料含有特殊字元 | 開啟檔案時加上 `encoding="utf-8"`，或在前處理階段清理 |

---

## 11. 建議的學習路線

1. **完成 Quick Start**：跑一次 `train` stage，理解輸出的 artifacts。
2. **閱讀設定檔**：嘗試修改 `epochs`、`batch_size`，觀察訓練時間與結果。
3. **啟用 tuning stage**：了解 Optuna 搜尋如何改善指標。
4. **探索 stability stage**：觀察模型在多次訓練的變異程度。
5. **進階擴充**：
   - 增加資料前處理
   - 加入新的任務（如 regression head）
   - 整合 LoRA 或量化技術以節省資源

---

## 12. 常用資源與參考

- [HuggingFace Transformers 文檔](https://huggingface.co/docs/transformers)
- [Optuna 官方文件](https://optuna.org/)
- [scikit-learn 指標與評估](https://scikit-learn.org/stable/modules/model_evaluation.html)
- [PyTorch DataLoader 說明](https://pytorch.org/docs/stable/data.html)

---

## 13. 附錄：術語小辭典

| 術語 | 解釋 |
|------|------|
| **Epoch** | 完整掃過訓練資料一次的過程 |
| **Batch Size** | 每次訓練迭代餵入模型的資料筆數 |
| **Learning Rate (lr)** | 控制梯度更新幅度，太大會震盪，太小收斂慢 |
| **FP16 / Mixed Precision** | 使用半精度浮點節省 GPU 記憶體，常見於支援 Tensor Cores 的 GPU |
| **Confusion Matrix** | 混淆矩陣，顯示真實與預測標籤的對照情形 |
| **Macro F1** | 對所有類別計算 F1 平均，適合衡量類別不平衡 |
| **Weighted F1** | 以類別樣本數加權的 F1 平均 |
| **Trial (Optuna)** | 超參數搜尋中的一次實驗 |

---

完成以上教學後，你應該能夠：
1. 從頭設定環境、放置資料並成功啟動整套 pipeline。
2. 了解各 stage 的作用與配置方式。
3. 針對不同需求（如 tuning、穩定性）調整設定。
4. 判讀輸出結果並著手進一步優化模型。

祝你在多任務分類的旅程一路順風！若有新想法（例如加上資料擴增、模型蒸餾），可在 `src/` 模組中自行擴充，也歡迎撰寫筆記分享給同學。
