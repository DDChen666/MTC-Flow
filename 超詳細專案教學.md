# 超詳細專案教學（給第一次接觸多任務分類的你）

> 作者註：這份教材假設你幾乎沒有接觸過這個專案、對 Python 深度學習架構也只有初步概念。為了做到「易懂、全面、極度紮實」，以下內容會比一般教學詳細得多，帶你從環境準備、概念理解、實際操作到延伸應用。建議邊讀邊操作，遇到不懂的字詞可先查詢或參考附錄中的小辭典。

---

## 目錄導覽

1. [為什麼需要這個專案？](#為什麼需要這個專案)
2. [概念暖身：兩分鐘理解核心名詞](#概念暖身兩分鐘理解核心名詞)
3. [環境準備與工具介紹](#環境準備與工具介紹)
4. [優雅建立專案工作夥伴：虛擬環境](#優雅建立專案工作夥伴虛擬環境)
5. [依賴安裝與結構巡禮](#依賴安裝與結構巡禮)
6. [資料是靈魂：如何整理並放入專案](#資料是靈魂如何整理並放入專案)
7. [設定檔大解剖：default.yaml 逐行讀懂](#設定檔大解剖defaultyaml-逐行讀懂)
8. [Logging 設定：為什麼要記錄？怎麼看？](#logging-設定為什麼要記錄怎麼看)
9. [Pipeline 運作全圖：主程序 main.py 的故事](#pipeline-運作全圖主程序-mainpy-的故事)
10. [四大 Stage 深入實戰](#四大-stage-深入實戰)
    - Split
    - Train
    - Tune（Optuna）
    - Stability
11. [輸出成果解讀：Metrics、CSV、圖表、Log](#輸出成果解讀metricscsv圖表log)
12. [進階技巧：解決常見問題與最佳化建議](#進階技巧解決常見問題與最佳化建議)
13. [進一步探索：延伸功能與擴充方向](#進一步探索延伸功能與擴充方向)
14. [教學實戰練習：由淺入深的練功路線](#教學實戰練習由淺入深的練功路線)
15. [術語小辭典](#術語小辭典)
16. [附錄：常見錯誤訊息與排除策略](#附錄常見錯誤訊息與排除策略)
17. [附錄：推薦參考資源](#附錄推薦參考資源)

---

## 為什麼需要這個專案？

在真實世界裡，一份使用者回饋同時可能包含多種資訊：主要問題是什麼？延伸的影響範圍又是什麼？傳統做法是訓練兩個模型各自預測 primary 與 secondary，但這樣會浪費資源，也難以利用兩個任務的關聯性。本專案採用「多任務學習（Multi-Task Learning）」架構，以一個 Transformer 編碼器同時學習兩個標籤層級，有幾項好處：

1. **節省資源**：共用同一個模型 backbone，訓練時間與硬體成本更低。
2. **提升泛化能力**：兩個任務共享資訊，有助於模型理解資料的結構。
3. **流程一致**：資料切分、訓練、超參數搜尋、穩定性測試都由同一套 pipeline 管理，降低人為疏忽。
4. **設定檔驅動**：所有參數透過 `configs/default.yaml` 控制，切換模型或調整流程不用改 Python 程式。

若你是：「
- 第一次接觸多任務學習；
- 想打造一個可重複、可擴充的 NLP 訓練流程；
- 希望把專案交給其他人也能快速上手」，

那你現在來對地方了。

---

## 概念暖身：兩分鐘理解核心名詞

| 名詞 | 生活類比 | 為什麼重要 |
|------|----------|-------------|
| **Primary Label** | 醫生先判斷病人是哪一科（內科、外科） | 我們的第一層分類，通常最重要 |
| **Secondary Label** | 再細分是哪個症狀（感冒、胃痛…） | 協助後續處理或指派人員 |
| **Transformer** | 具備多重注意力的閱讀器，可以同時關注句子不同位置 | 我們使用的模型骨幹（例如 DeBERTa） |
| **Pipeline** | 組裝線，控制每個 Stages 依序運作 | 確保流程可重複、可自動化 |
| **Stage** | 產線中的工作站（切資料、訓練、調參…） | 可依需求開關，不用手動跑許多腳本 |
| **Optuna** | 智慧實驗助理，幫忙試不同超參數 | 節省手動調參時間 |
| **Artifact** | 產出物（報表、圖表、紀錄） | 留存訓練證據，方便比較與回溯 |

---

## 環境準備與工具介紹

### 3.1 需要哪些軟體？

1. **Python 3.9+**：建議 64-bit，安裝方式：
   - Windows：到 [python.org](https://www.python.org/downloads/) 下載並勾選「Add to PATH」
   - macOS：建議使用 Homebrew `brew install python@3.11`
2. **Git**：版本控管與拉取專案用。
3. **CUDA & 驅動（選擇性）**：若使用 NVIDIA GPU，需要對應版本的 CUDA / cuDNN。
4. **Visual Studio Code 或你習慣的編輯器**：建議裝 Python、YAML、Markdown 插件。

### 3.2 建議的開發習慣
- 保持虛擬環境乾淨：每個專案有自己的 venv。
- 善用 `.gitignore`，避免把資料、模型權重推到遠端。
- 先閱讀 README 或 docs 了解整體流程，再動手改。

---

## 優雅建立專案工作夥伴：虛擬環境

### 4.1 為什麼要使用 venv？
- 避免不同專案的套件相互干擾。
- 可以快速重建環境（假如壞掉，就重建 venv）。

### 4.2 建立與啟動

```powershell
# Windows PowerShell
python -m venv venv
.\venv\Scripts\Activate.ps1
```
```bash
# macOS / Linux / WSL
python3 -m venv venv
source venv/bin/activate
```

> 檢查：啟動成功後命令列前面會出現 `(venv)`。

### 4.3 停用虛擬環境
```bash
deactivate
```

---

## 依賴安裝與結構巡禮

### 5.1 安裝專案依賴
```powershell
pip install --upgrade pip
pip install -e .
```
- `pip install -e .`：“editable mode”，表示安裝的是專案本身，你修改程式碼會立即生效。
- 依賴清單寫在 `pyproject.toml`。

### 5.2 專案結構（節錄）
```
.
├── configs/                  # 設定檔
│   ├── default.yaml
│   └── logging.yaml
├── docs/                     # 文件（含本教學與簡易指令）
├── input_train_and_test_json/ # 資料預設位置
├── src/
│   ├── data/                # 讀寫資料、切分
│   ├── mtc/                 # 多任務模型與訓練核心
│   ├── pipeline/            # Stage 邏輯
│   ├── utils/               # 設定、logging 工具
│   └── main.py              # 入口程式
├── artifacts/               # 執行後成果
├── train_mtc.py 等舊腳本    # 封裝新架構的 CLI
└── README.md / docs         # 使用說明
```

---

## 資料是靈魂：如何整理並放入專案

### 6.1 來源與格式
- 檔案類型：可用 JSON 或 JSON Lines（JSONL）。
- 每筆至少包含：
  ```json
  {
    "text": "使用者回報內容...",
    "primary": "BUG",
    "secondary": "ACCOUNT"
  }
  ```
- 若欄位名稱不同，記得更新 `configs/default.yaml` 中的 `data.text_field` 等欄位。

### 6.2 預設放置方式
- 把下列檔案放入 `input_train_and_test_json/`
  - `train_set_20250919_181918.json`
  - `test_set_20250919_181918.json`
- 檔名不需要完全一致，但 config 內需填寫正確。

### 6.3 尚未切分資料？
- 你可以先準備一份 `all_data.json`，然後啟用 split stage：
  ```yaml
  data:
    split:
      enabled: true
      input_path: ../data/raw/all_data.json
  ```
  執行 `python -m src.main --stages split` 後，會自動產生 train/test 檔案。

---

## 設定檔大解剖：default.yaml 逐行讀懂

> 建議打開 `configs/default.yaml` 對照閱讀。此檔案採 YAML 格式，縮排代表層次結構。

### 7.1 頂層結構
```yaml
project:
  ...
pipeline:
  ...
data:
  ...
labels:
  ...
training:
  ...
tuning:
  ...
stability:
  ...
```

### 7.2 project 區塊
| 欄位 | 功能 | 建議值 |
|------|------|--------|
| `seed` | 控制隨機性，保障可重現性 | 42（或任何固定數） |
| `output_root` | 全部輸出檔案的父資料夾 | 建議保持 `../artifacts` |
| `logging.config` | Logging 設定檔路徑 | 預設 `./logging.yaml` |
| `logging.level` | 預設 log 等級 | INFO |

### 7.3 pipeline 區塊
```yaml
pipeline:
  stages:
    - split
    - train
    - tune
    - stability
```
- 代表執行順序。你可以移除或改順序，例如 `[train, tune]`。
- 即使列在這裡，如果某個 stage 的 `enabled: false`，實際也會略過。

### 7.4 data 區塊
| 欄位 | 說明 |
|------|------|
| `root_dir` | train/test 的資料夾 |
| `train_file` / `test_file` | 檔名（相對於 root_dir） |
| `text_field` 等 | 欄位名稱，若資料欄位不同請修改 |
| `split.enabled` | 是否啟用資料切分 |
| `split.test_size` | 測試集比率（0~1） |
| `split.stratify_key` | 分層抽樣依據欄位（預設 primary） |
| `split.timestamp_format` | 輸出檔案命名格式 |

### 7.5 labels 區塊
- 列出 Primary / Secondary 類別清單。
- 程式會自動建立 label ↔ id 映射。
- 若訓練資料中出現未列出的類別，會在 `ReviewDataset` 被跳過。

### 7.6 training 區塊
| 欄位 | 說明 | 常見操作 |
|------|------|----------|
| `enabled` | 是否訓練模型 | 最初務必設 true |
| `model_name` | HuggingFace 模型名稱 | 可改成 `hfl/chinese-macbert-base` 等 |
| `output_subdir` | 輸出子資料夾名稱 | 預設 `training` |
| `max_length` | tokenizer 截長度 | 避免長度過長造成 GPU 爆炸 |
| `epochs` | 訓練輪數 | 視資料量調整 |
| `batch_size` / `eval_batch_size` | 批次大小 | 避免顯示記憶體不足 |
| `learning_rate` | 學習率 | 常用值 2e-5, 3e-5 |
| `dropout` | Dropout 機率 | 0.1~0.3 |
| `alpha` / `beta` | Primary / Secondary 損失權重 | 調整任務重要性 |
| `use_focal` | 是否使用 Focal Loss | 正負樣本極不平衡時設 true |
| `weighted_sampler` | 啟用 WeightedRandomSampler | 類別不平衡時有效 |
| `fp16_auto` | 使用混合精度 | 有 GPU 時建議 true |
| `evaluation` 子欄位 | 決定輸出哪些成果 | 可視需求關閉部分檔案 |

### 7.7 tuning 區塊（Optuna）
- `enabled`：啟用或關閉
- `trials`：迭代數
- `direction`：最大化或最小化（通常 `maximize`）
- `search_space`：可分為 categorical、uniform、loguniform、int 等

### 7.8 stability 區塊
- 用於檢查不同 seed 下的表現一致性。
- `runs`：執行幾次訓練
- `base_seed`：第一個訓練的 seed，之後依序 +1

---

## Logging 設定：為什麼要記錄？怎麼看？

### 8.1 logging.yaml 結構
```yaml
version: 1
formatters:
  standard: ...
handlers:
  console: ...
  file: ...
loggers:
  "": ...
  pipeline: ...
  src: ...
```
- `console` handler：輸出到終端機
- `file` handler：寫入 `artifacts/pipeline.log`
- 預設 root logger (`""`) 與 `pipeline`、`src` 都使用這兩個 handler。

### 8.2 閱讀 log 的技巧
- 每列 log 格式：`時間 | 等級 | logger 名稱 | 訊息`
- 例如：`2025-09-19 08:15:02 | INFO | pipeline.stages | Starting training run ...`
- 若遇到錯誤，先查 `ERROR` 或 `WARNING` 行。

---

## Pipeline 運作全圖：主程序 main.py 的故事

### 9.1 CLI 參數
- `--config`：設定檔路徑（預設 `configs/default.yaml`）
- `--stages`：顯式指定要執行的 stage 順序（覆蓋設定檔）
- `--list-stages`：列出可用 stage

### 9.2 執行流程
1. 解析 CLI 參數
2. 載入設定檔 (`load_project_config`)
3. 初始化 logging
4. 建立 `PipelineContext`
5. 依序執行 stage handler

### 9.3 PipelineContext 內容
- `config`：ProjectConfig dataclass
- `train_data_path` / `test_data_path`：stage 之間的資料溝通管道
- `label_schema`：標籤映射（由 labels 區塊建構）
- `last_training_result`：最近一次訓練結果（可供 tune/stability 使用）

---

## 四大 Stage 深入實戰

### 10.1 Split Stage
- 目的：從原始資料產生 train/test
- 主程式：`src/data/split.py`
- 流程：
  1. 讀取 JSON / JSONL
  2. 使用 `train_test_split`（scikit-learn）
  3. 依模板命名輸出檔案
  4. 回寫 `context` 的 `train_data_path` / `test_data_path`
- 注意：
  - 必須啟用 `split.enabled`
  - `stratify_key` 預設使用 `primary`，確保分層抽樣

### 10.2 Train Stage
- 主程式：`src/mtc/training.py`
- 核心步驟：
  1. 載入訓練與測試資料
  2. 建立 tokenizer（`AutoTokenizer`）
  3. 建立 dataset（`ReviewDataset`）
  4. 計算 class weights（選用）
  5. 初始化模型（`MultiTaskClassifier`）
  6. 使用 `Trainer` 訓練
  7. 評估並儲存成果
- `MultiTaskClassifier` 架構：
  - Encoder：`AutoModel.from_pretrained(model_name)`
  - Head：兩個線性層 (`primary_head`, `secondary_head`)
  - Loss：依 `use_focal` 決定使用 FocalLoss 或 CrossEntropy

### 10.3 Tune Stage（Optuna）
- 主程式：`src/pipeline/stages.py` 的 `run_tuning_stage`
- 流程：
  1. 讀取 `search_space`
  2. Optuna 依據分佈抽樣參數（`trial.suggest_*`）
  3. 複製 training 設定並覆寫參數
  4. 呼叫 `train_and_evaluate` 執行一次訓練
  5. 回傳 macro F1 平均
  6. 儲存最佳結果與 trial 歷史
- 建議：先確定 baseline 執行正常再啟用 tuning。

### 10.4 Stability Stage
- 主程式：`run_stability_stage`
- 流程：
  1. 以 `base_seed` 為起點，依次執行 `runs` 次
  2. 每次訓練會輸出完整 artifact
  3. 最後彙整 `macro_avg_mean`、`macro_avg_std` 等統計
- 用途：判斷模型是否容易被 seed 影響；若標準差過大，可能需要調整資料或訓練策略。

---

## 輸出成果解讀：Metrics、CSV、圖表、Log

| 檔案 | 位置 | 內容 | 用途 |
|------|------|------|------|
| `metrics_<timestamp>.json` | `artifacts/training/...` | Primary / Secondary accuracy、F1、classification report、confusion matrix | 最重要的評估資料 |
| `confusion_primary_*.csv` | 同上 | 混淆矩陣表格（以 CSV 表示） | 快速檢視哪些類別被混淆 |
| `confusion_primary_*.png` | 同上 | 混淆矩陣熱力圖 | 報告用圖表 |
| `predictions_*.csv` | 同上 | 詳列每筆資料的真實與預測標籤 | 進一步分析錯誤案例 |
| `label_map.json` | 同上 | 標籤與 id 對應 | 方便日後解析 |
| `optuna_best.json` | `artifacts/tuning/` | 最佳 trial 結果 | 超參數調整參考 |
| `stability_summary.json` | `artifacts/stability/` | 多次訓練的平均＆標準差 | 評估穩定性 |
| `artifacts/pipeline.log` | 根目錄 | 執行過程的 log | 追蹤流程與排錯 |

---

## 進階技巧：解決常見問題與最佳化建議

### 12.1 資料不平衡怎麼辦？
- 啟用 `training.weighted_sampler`
- 啟用 `training.weight_primary`/`weight_secondary`
- 使用 Focal Loss (`use_focal: true`)
- 觀察混淆矩陣，針對常見混淆類別進行資料增強

### 12.2 模型表現不如預期？
- 檢查資料是否清洗乾淨（空白、錯字、亂碼）
- 調整 `max_length`，避免截斷重要資訊
- 嘗試不同模型（更大/更小）
- 使用 tuning stage 調整學習率、batch size 等

### 12.3 訓練太慢或 GPU 不夠？
- 降低 `max_length`
- 使用 `fp16_auto: true`（若 GPU 支援）
- 減少 `batch_size`
- 使用較小模型（例如 `bert-base`）
- 若硬體受限，可考慮 LoRA 或 Adapter（需自行擴充程式碼）

### 12.4 想要自動化？
- 編寫 shell script 或 PowerShell Script
- 在 GitHub Actions 設置 CI（需安裝依賴與登入資料來源）
- 搭配 cron job 定期更新模型

---

## 進一步探索：延伸功能與擴充方向

### 13.1 模型層面
- **LoRA / Adapter**：降低 fine-tune 成本（需在 `mtc/modeling.py` 擴充）
- **多頭輸出**：除了 primary/secondary，再加上情緒分析或屬性分類
- **知識蒸餾**：以較大模型為師，訓練小模型

### 13.2 資料處理
- **資料清洗**：去除 HTML、網址、重複資料
- **資料增強**：替換同義詞、回譯、隨機插入等
- **多語系擴充**：加入語言辨識器，分語系再針對性訓練

### 13.3 評估指標
- 新增 ROC-AUC、PR Curve
- 針對特定類別計算 recall / precision
- 使用 `mlflow` 或 `wandb` 管理實驗記錄

### 13.4 部署與應用
- 將最佳模型導出為 `.pt` 或 ONNX
- 建立推論 API（FastAPI / Flask）
- 結合情境：客服工單自動分類、QA 路由、風險預警

---

## 教學實戰練習：由淺入深的練功路線

### 練習 1：跑通 baseline
1. 準備現成 train/test
2. `python -m src.main --stages train`
3. 確認 `metrics.json`

### 練習 2：資料切分
1. 只有原始資料 all.json
2. 設定 `split.enabled: true`
3. 執行 `split -> train`，觀察產生的檔案

### 練習 3：超參數搜尋
1. 啟用 `tuning.enabled`
2. 設 `trials: 5`（先小數量）
3. 觀察 `optuna_trials.csv`

### 練習 4：穩定性測試
1. `stability.enabled: true`
2. `runs: 3`
3. 比較 `stability_summary.json` 與 baseline 的差異

### 練習 5：自訂模型
1. 改 `training.model_name`
2. 若模型輸出維度不同，確認 `MultiTaskClassifier` 是否支援
3. 實驗不同 `alpha`、`beta` 權重

---

## 術語小辭典

| 英文 | 中文 | 解釋 |
|------|------|------|
| Epoch | 訓練輪 | 模型掃過一次完整訓練資料集 |
| Batch Size | 批次大小 | 一次輸入模型的樣本數量 |
| Learning Rate | 學習率 | 控制梯度更新幅度 |
| FP16 | 半精度 | 使用 16-bit 浮點數加速訓練 |
| Focal Loss | 焦點損失 | 對難學樣本加大權重 |
| Weighted Sampler | 加權抽樣 | 讓稀有類別被更頻繁抽中 |
| Optuna Trial | 調參實驗 | 每一次超參數組合的訓練 |
| Confusion Matrix | 混淆矩陣 | 真實 vs 預測標籤的計數表 |

---

## 附錄：常見錯誤訊息與排除策略

| 訊息 | 可能原因 | 解决方式 |
|------|----------|----------|
| `FileNotFoundError` | 檔案路徑錯誤 | 檢查 `root_dir` 與檔名是否一致 |
| `UnicodeDecodeError` | 檔案編碼非 UTF-8 | 重新存成 UTF-8，或在讀取時指定 encoding |
| `CUDA out of memory` | GPU 記憶不足 | 降低 batch size 或 max_length |
| `ImportError: optuna` | 未安裝 optuna | `pip install optuna` 或關閉 tuning stage |
| `ValueError: stratify` | 資料不足以分層 | 檢查是否有類別樣本小於 2 |

---

## 附錄：推薦參考資源

1. [HuggingFace Transformers 官方文檔](https://huggingface.co/docs/transformers)
2. [Optuna 入門指南](https://optuna.readthedocs.io/)
3. [scikit-learn Model Evaluation](https://scikit-learn.org/stable/modules/model_evaluation.html)
4. [PyTorch Lightning vs. HuggingFace Trainer 比較](https://pytorch-lightning.readthedocs.io/)
5. [多任務學習綜述論文 (Survey)](https://arxiv.org/abs/1706.05098)

---

恭喜你讀到這裡！現在你已經掌握：
- 為什麼要採多任務架構？
- 如何準備環境與資料？
- 如何閱讀與修改設定檔？
- 四大 stage 的細節與彼此關聯？
- 遇到問題如何排錯與最佳化？

接下來，請動手實作、記錄實驗、發掘更多延伸功能。希望這份「超詳細專案教學」能成為你在多任務分類旅程中可靠的夥伴。祝順利！
